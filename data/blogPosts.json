[
    {
        "name": "2019-01-30-Introducing-Rho-Graphics.md",
        "path": "_posts/2019-01-30-Introducing-Rho-Graphics.md",
        "sha": "9d0038184ee970877b2cc7d6fc6083c405302c84",
        "size": 3784,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-01-30-Introducing-Rho-Graphics.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-01-30-Introducing-Rho-Graphics.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/9d0038184ee970877b2cc7d6fc6083c405302c84",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-01-30-Introducing-Rho-Graphics.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-01-30-Introducing-Rho-Graphics.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/9d0038184ee970877b2cc7d6fc6083c405302c84",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-01-30-Introducing-Rho-Graphics.md"
        },
        "md": "---\nlayout: post\ntitle: Introducing Rho Data Visualization\nauthor: Ryan Bailey\n---\n\nWe work in clinical research and our industry is driven by data. Every phase of our trials requires us to collect, monitor, analyze, and report data. While each of these steps is equally important, reporting is arguably the most impactful step. When we create reports, we invite our audience to interpret the data and draw meaningful conclusions.\n \n<img src=\"{{ site.baseurl }}/images/beeswarm.png\" align=\"right\" /> Is the trial being conducted correctly? Is participant enrollment on schedule? Are we protecting our participants' safety? Was the investigational product effective? Was our hypothesis confirmed? We rely on effective data reporting to answer these questions.\n \nUnfortunately, our industry doesn't always use the best tools or practices when it comes to data reporting. If you've ever had to make sense of 50 pages of data listings or spend hours creating figures using spreadsheet software, you know what we mean. If these methods feel outdated, it's because they are. The good news is that there are plenty of alternatives available to us, and in recent years, important stakeholders in our field have acknowledged our need to branch out, adapt, and evolve.\n \nGranted, some of the formats for reporting are mandated by formal regulations. We may not be able to do much about these reports, but many of the methods we use to report data are left up to us as analysts and data scientists. As such, we argue that clinical researchers have a responsibility to do the data justice and communicate them as clearly and effectively as possible.\n\n <img src=\"{{ site.baseurl }}/images/sunburst.png\" align=\"right\" /> What does this mean for our industry? It means looking for newer and better ways to communicate data. It means thinking carefully about how the method of reporting impacts perception and comprehension of data. It means researching novel technology tools for sharing data. \n \nRho took these challenges to heart. In 2014, we created a Data Science team to research and promote the best practices and tools for visualizing and reporting data. The team was founded by a few senior biostatisticians, web programmers, and project managers who had years of experience directly supporting clinical trials. This first-hand experience with clinical research gave our team a unique perspective on the data reporting needs at all stages of clinical research from study design, to participant enrollment, monitoring, data collection, analysis, data exploration, to publication and reporting. Our Data Science team marries clinical research experience with the technical skillset to create innovative, cutting-edge data visualizations in support of our research projects.\n \n<img src=\"{{ site.baseurl }}/images/scatter.png\" align=\"right\" />  In support of our projects, the has developed hundreds of novel graphics for both static reports and interactive web-based use. In both cases, the response from our clients and research partners has been overwhelmingly positive. Beginning in 2015, we began taking the best of our visualizations and turning them into reusable, open source tools developed on [GitHub](https://github.com/RhoInc).  At the time of this post, we have over 50 publicly available repositories available for anyone to use.  \n\nData visualization has tremendous potential to improve the way we communicate, understand, and interact with data. If you would like to learn more about Rho’s data visualization work, contact us: [graphics@rhoworld.com](mailto:graphics@rhoworld.com).\n\n*This post [originally appeared](http://resources.rhoworld.com/blog/resourcebrcenter/rhos-blog/introducing-rhos-graphics-group-0) on [Rho's Corporate Blog](http://resources.rhoworld.com/blog).*\n"
    },
    {
        "name": "2019-01-31-Interactive-Adverse-Events-Explorer.md",
        "path": "_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md",
        "sha": "c19c22128a8e38eda5c7f96fb13248e29fd65125",
        "size": 4263,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/c19c22128a8e38eda5c7f96fb13248e29fd65125",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/c19c22128a8e38eda5c7f96fb13248e29fd65125",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-01-31-Interactive-Adverse-Events-Explorer.md"
        },
        "md": "---\nlayout: post\ntitle: Interactive Adverse Events Explorer\n---\n\nIn the conduct of clinical trials, few tasks are as important as monitoring and reporting adverse events (AEs). The standard method of reporting AEs is to compile detailed listings of every adverse event reported in a study. Medical monitors and regulatory bodies are then tasked with reviewing these listings to monitor patient safety and search for complications and side effects associated with an investigational product.\n\nFor studies with large participant enrollment, severe diseases, complex treatments, or long treatment timelines, thousands of AEs may be reported, leading to scores of pages of listings. While comprehensive reporting is necessary, the current approach of creating page after page of listings is inefficient. Worse, this reporting approach creates a risk that that clinically-relevant safety signals will be obscured by the sheer volume of events reported.\n\nMembers of Rho's Data Science team recognized an opportunity to improve upon this paradigm by creating an [interactive web-based Adverse Event Explorer](http://rhoinc.github.io/aeexplorer/test-page/), which gives study monitors a more intuitive and powerful way to query AE data in real time.\n\n![AE Explorer](https://resources.rhoworld.com/hs-fs/hub/161293/file-2625108093-png/ae-explorer.png?width=594&name=ae-explorer.png)\n\nThe AE Explorer contains all of the information available in standard listings, but our tool adds simple graphics to aid with data comprehension and applies web-based interactivity to give users the ability to search their data in real-time.\n\nThe default view of the Explorer is a single-screen display of AEs grouped by System Organ Class. Beside each row, a dot plot portrays the adverse event incidence for each treatment groups, which gives users a simple graphical comparison for their data. An additional graphic can be displayed to indicate the size of the difference between groups and whether the difference is statistically significant. Since humans more readily process graphics than abstract characters like numbers and letters, the graph helps bring the \"story\" of the data to life.\n\nThese graphics provide an intuitive visual component to the traditional AE report, but the real strength of the AE Explorer is in the interactive features that let users query the data in real time.\n\nAt a single click, the System Organ Class rows can be expanded to show the nested Preferred Terms underneath − each row with it's own data and dot plot. Users can hover their cursor over the graphic elements to show additional detail about the data points. For any given AE, users can drill down to see a participant-level summary of the underlying data.\n\nEvents can be filtered by prevalence so that only AEs above a particular threshold (e.g., 5%) are displayed. Fully-customizable filters can also be created to allow users to filter their data at a click. For instance, users can filter by severity to drop out mild and moderate adverse events to focus only on events classified as severe or life-threatening. A search bar also lets users instantly search the listings for terms of interest (e.g., \"headache\").\n\nEnd users consistently report positive experiences when using the Explorer, noting that the tool saves time and gives them improved understanding of the data. We anticipate that the clinical trials industry will increasingly incorporate these types of powerful analytic tools into routine clinical trial management and reporting. In fact, a study-specific instance of our AE Explorer was recently used to report AE data for an [article published in the New England Journal of Medicine](http://www.nejm.org/doi/full/10.1056/NEJMoa1414850).\n\nOur AE Explorer improves the reporting and monitoring of AEs by applying data visualizations and contemporary web browsing practices to the traditional process. You can learn more about the AE Explorer and [try it out](http://rhoinc.github.io/aeexplorer/test-page/) for yourself on Rho's public [graphics-sharing website](https://rhoinc.github.io/graphics/).\n\n*This post [originally appeared](http://resources.rhoworld.com/blog/introducing-the-adverse-events-explorer) on [Rho's Corporate Blog](http://resources.rhoworld.com/blog).*\n"
    },
    {
        "name": "2019-02-05-safetyGraphics-on-CRAN.md",
        "path": "_posts/2019-02-05-safetyGraphics-on-CRAN.md",
        "sha": "2227e5915cd42deaa6eb27035e2e6ae14343aecb",
        "size": 2398,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-02-05-safetyGraphics-on-CRAN.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-02-05-safetyGraphics-on-CRAN.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/2227e5915cd42deaa6eb27035e2e6ae14343aecb",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-02-05-safetyGraphics-on-CRAN.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-02-05-safetyGraphics-on-CRAN.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/2227e5915cd42deaa6eb27035e2e6ae14343aecb",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-02-05-safetyGraphics-on-CRAN.md"
        },
        "md": "---\nlayout: post\ntitle: safetyGraphics R Library released to CRAN\nauthor: Jeremy Wildfire\n---\n\nWe're excited to report that the `safetyGraphics` R package is now on [CRAN](https://cran.r-project.org/web/packages/safetyGraphics/index.html)!  `safetyGraphics` is designed to make it easy to create interactive graphics related to clinical trial safety. We're still in beta, but are very excited about the progress so far - here's a sneak peek: \n\n![edishapp-take2_smallish](https://user-images.githubusercontent.com/3680095/51296057-e3195380-19df-11e9-971a-430c3be930a4.gif)\n\nYou can try the shiny app for yourself by pasting the following code in to RStudio:\n\n```\nintsall.packages(\"safetyGraphics)\" \nlibrary(\"safetyGraphics\") \nsafetyGraphicsApp()\n```\n\nRho collaborates on the `safetyGraphics` package as members of the ASA Biopharm/DIA Safety Working Group’s Interactive Safety Graphics Taskforce, which combines stakeholders from across the pharmaceutical industry, including the FDA. To learn more about this project you can:\n\n- See the package on [CRAN](https://cran.r-project.org/web/packages/safetyGraphics/index.html).\n- View the [vignette](https://cran.r-project.org/web/packages/safetyGraphics/vignettes/shinyUserGuide.html) for detailed guidance on using the Shiny application.\n- Explore the [github repo](https://github.com/ASA-DIA-InteractiveSafetyGraphics/safetyGraphics) for the package. Issues and pull requests strongly encouraged!\n- Look at our [rstudio::conf(2019) ePoster](https://github.com/RhoInc/RStudioConf2019-ePoster) about this project. \n- Check out the underlying [javascript library](https://github.com/ASA-DIA-InteractiveSafetyGraphics/safety-eDISH) used to create the [eDish Chart](https://asa-dia-interactivesafetygraphics.github.io/safety-eDISH/).\n- Try out a hosted version of the [shiny app](https://becca-krouse.shinyapps.io/safetyGraphicsApp/) (or run it locally using the code above).\n- See Rho's [other interactive graphics](https://rhoinc.github.io/safety-explorer-suite/) for safety monitoring.  We also wrote [a paper](https://journals.sagepub.com/doi/abs/10.1177/2168479018754846) about these. Our plan is to add some of them to the `SafetyGraphics` package in future releases.\n- Take a look at the [technical framework](https://user-images.githubusercontent.com/3680095/51296179-6f2b7b00-19e0-11e9-841a-afc2964a7e1a.png) being used to create the chart.\n\n\n\n"
    },
    {
        "name": "2019-02-26-Open-Source-is-Good-Science.md",
        "path": "_posts/2019-02-26-Open-Source-is-Good-Science.md",
        "sha": "267e073c7411a1eab33de09a7e855e944cae477d",
        "size": 4022,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-02-26-Open-Source-is-Good-Science.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-02-26-Open-Source-is-Good-Science.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/267e073c7411a1eab33de09a7e855e944cae477d",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-02-26-Open-Source-is-Good-Science.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-02-26-Open-Source-is-Good-Science.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/267e073c7411a1eab33de09a7e855e944cae477d",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-02-26-Open-Source-is-Good-Science.md"
        },
        "md": "---\nlayout: post\ntitle: Embracing Open Source as Good Science\nauthor: Ryan Bailey\n---\n<img src=\"{{ site.baseurl }}/images/open.png\" align=\"right\" /> Sharing.  It's one of the earliest lessons your parents try to teach you - don't hoard, take turns, be generous.  Sharing is a great lesson for life.  Sharing is also a driving force behind scientific progress and software development.  Science and software rely on communal principles of transparency, knowledge exchange, reproducibility, and mutual benefit.  \n\nThe practice of open sharing or open sourcing has advanced these fields in several ways:\n* [promoting better science](https://opensource.com/education/11/10/default-open-scientific-method) through transparency, peer review, and knowledge promotion\n* increasing [community engagement](https://opensource.com/open-organization/16/5/appreciating-full-power-open) by inviting scrutiny, feedback, mutual sharing, and collaboration\n* aligning with [government policy](https://open.usa.gov/) on openness and visibility in publicly-funded work\n\nWe also feel strongly that the impetus for open sharing is reflected in [Rho's core values](http://www.rhoworld.com/rho/about/our-values) - especially team culture, innovation, integrity, and quality.  Given our values, and given our role in conducting science and creating software, we've been exploring ways that we can be more active in the so-called \"sharing economy\" when it comes to our work.  \n\nOne of the ways we have been fulfilling this goal is to release our statistical and data visualization tools as freely-accessible, open source libraries on GitHub.  GitHub is one of the world's largest open source platforms for virtual collaboration and code sharing.  GitHub allows users to actively work on their code online, from anywhere, with the opportunity to share and collaborate with other users.  As a result, we not only share our code for public use, we also invite feedback, improvements, and expansions of our tools for other uses. \n\nWe released our first open source tool - the openFDA Adverse Event Explorer - in June 2015.  Now we have 26 team members working on 28 public projects, and that number has been growing rapidly.  The libraries and tools we've been sharing have a variety of uses: monitor safety data, track project metrics, visualize data, summarize every data variable for a project, aid with analysis, optimize SAS tools, and explore population data.\n\nMost repositories include examples and wikis that describe the tools and how they can be used.  An example of one of these tools, the Population Explorer is shown below.\n\n## Interactive Population Explorer\n<img src=\"{{ site.baseurl }}/images/population-explorer.png\"/>\n\n*Access summary data on study population and subpopulations of interest in real time.*\n\nOne of over 50 public projects on Rho's GitHub page - available at: [https://github.com/RhoInc/](https://github.com/RhoInc)\n\nIn the coming months, we plan to use the blog to highlight a few of our different open source tools.  We invite you to check back/subscribe to learn more about the tools we're making available to the public.  We also encourage you to peruse the work for yourself on our [GitHub page](https://github.com/RhoInc).\n\nWe are excited to be hosting public code and instructional wikis in a format that allows free access and virtual collaboration, and hope that an innovative platform like GitHub will give us a way to share our tools with the world and refine them with community feedback.  As science and software increasingly embrace open source code, we are changing the way we develop tools and optimizing the way we do clinical research while staying true to our core purpose and values.\n\nIf you have any questions or want to learn more about one of our projects, email us at: [graphics@rhoworld.com](mailto:graphics@rhoworld.com).\n\n*This post [originally appeared](http://resources.rhoworld.com/blog/embracing-open-source-as-good-science) on [Rho's Corporate Blog](http://resources.rhoworld.com/blog).*\n"
    },
    {
        "name": "2019-03-22-Relaunching-the-Rho-Graphics-website.md",
        "path": "_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md",
        "sha": "1cfa7f2bc6b784556ce362da1f6947e889533577",
        "size": 3083,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/1cfa7f2bc6b784556ce362da1f6947e889533577",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/1cfa7f2bc6b784556ce362da1f6947e889533577",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-03-22-Relaunching-the-Rho-Graphics-website.md"
        },
        "md": "---\nlayout: post\ntitle: Relaunching the Rho Graphics Website\nauthor: Jeremy Wildfire\n---\n\nOur team is all about developing [open-source tools](https://rhoinc.github.io/blog/Open-Source-is-Good-Science/), so we do lots of our work in public. Yet we've been pretty bad about maintaining a decent public website in recent years.\nThat ends today! We're happy to announce the launch of the [new Rho Graphics website](https://rhoinc.github.io/graphics).\n\nThe site includes a [homepage](https://rhoinc.github.io/graphics) along with links to our [code on GitHub](https://github.com/RhoInc) and to stand-alone pages tracking our [publications](https://rhoinc.github.io/publication-library), [visualizations](https://rhoinc.github.io/viz-library) (shown below), [data](https://rhoinc.github.io/data-library) and, of course, this [blog](https://rhoinc.github.io/blog).\n\n<img style=\"border:2px solid #999\" src=\"{{ site.baseurl }}/images/relaunching-the-rho-graphics-website.png\" align=\"center\" />\n\nOur old website was pretty clunky, and required painful FTP file-swapping torture to update.\nWe want to spend our time making great tools and writing about them on this blog, so our goal was to make a site that (1) leverages all of our existing open source work and (2) is easy to maintain.\nWe made several design decisions with those goals in mind:\n\n- __Outsource hosting__ - The site is built using the super simple [GitHub pages](https://pages.github.com/) framework. We'll redirect our old graphics.rhoworld.com URL and shut down the server as soon as we're done migrating content.\n- __Simple modular design__ - Each page gets its own GitHub repo and build process, including the new [data-library](https://rhoinc.github.io/data-library) and [publication-library](https://rhoinc.github.io/publication-library) pages.\n- __Easy to use blog__ - Write posts in markdown & automatically publish with [Jekyll-now](https://github.com/barryclark/jekyll-now).\n- __No more stand-alone examples__ - Instead we updated [viz-library](https://rhoinc.github.io/viz-library) to automatically [scrape examples](https://github.com/RhoInc/viz-library/blob/master/scripts/scrapeExamples.js) and [take snapshots](https://github.com/RhoInc/viz-library/blob/master/scripts/takeScreenshots.js) from the `\\test-page` folders in our graphics repos.\n- __Easy Updates__ - We've documented a simple processes for [adding publications](https://github.com/RhoInc/publication-library#adding-a-publication) and [data files](https://github.com/RhoInc/data-library#adding-a-file) and [writing blog posts](https://github.com/RhoInc/blog#creating-a-post).\n- __Automated Builds__ - Our new homepage and viz-library pages are fully automated, with all content coming from GitHub repos. We've [set up automated builds with TravisCI](https://docs.travis-ci.com/user/deployment/pages/) so that the pages update nightly - no human intervention needed!\n\nWith these changes, we'll be able to focus more energy than ever on creating great open-source tools while avoiding the painful overhead of manually maintaining a sprawling webpage.\n"
    },
    {
        "name": "2019-06-19-safetyGraphics-Version-1-is-live.md",
        "path": "_posts/2019-06-19-safetyGraphics-Version-1-is-live.md",
        "sha": "7a152f29945457b53faab3173b58d5443f0e70c1",
        "size": 1385,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-06-19-safetyGraphics-Version-1-is-live.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-06-19-safetyGraphics-Version-1-is-live.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/7a152f29945457b53faab3173b58d5443f0e70c1",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-06-19-safetyGraphics-Version-1-is-live.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-06-19-safetyGraphics-Version-1-is-live.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/7a152f29945457b53faab3173b58d5443f0e70c1",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-06-19-safetyGraphics-Version-1-is-live.md"
        },
        "md": "---\nlayout: post\ntitle: safetyGraphics Version 1.0\nauthor: Jeremy Wildfire\n---\n\nWe're excited to report that the `safetyGraphics` R package is now officially out of Beta! Version 1.0 of the package has been [released on github](https://github.com/SafetyGraphics/safetyGraphics/releases) and sent to [CRAN](https://cran.r-project.org/web/packages/safetyGraphics/index.html). Try it [here](https://becca-krouse.shinyapps.io/safetyGraphicsApp/)!\n\n<img style=\"border:2px solid #999\" src=\"{{ site.baseurl }}/images/safetyGraphics_v1_0.gif\" align=\"center\" />\n\nAs discussed in our [previous post]({{ site.baseurl }}/blog/safetyGraphics-on-CRAN/), `safetyGraphics` makes it easy to create interactive graphics related to clinical trial safety. As shown above, Version 1 adds 5 new interactive graphics and a detailed help page with both technical and clinical workflows. You can try out a hosted version of the [shiny app](https://becca-krouse.shinyapps.io/safetyGraphicsApp/) or see the [github page](https://github.com/SafetyGraphics/safetyGraphics) for details on running the package locally.\n\nThis project is run by the [Interactive Safety Graphics (ISG) subteam of the ASA Biopharm-DIA Safety Working Group](https://safetygraphics.github.io/), and we're still actively developing the package, so [we'd love to hear from you](https://github.com/SafetyGraphics/safetyGraphics/issues/new). \n"
    },
    {
        "name": "2019-07-09-Make-GitHub-Your-Code-Repository.md",
        "path": "_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md",
        "sha": "831c1db973f671adb6d80a19b732615b82622a97",
        "size": 4277,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/831c1db973f671adb6d80a19b732615b82622a97",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/831c1db973f671adb6d80a19b732615b82622a97",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-07-09-Make-GitHub-Your-Code-Repository.md"
        },
        "md": "---\nlayout: post\ntitle: Make GitHub Your Code Repository\nauthor: Spencer Childress\n---\n\n_This post shares information from our presentation at this year's [PhUSE Connect conference](https://www.phuse.eu/us-connect19)._\n_The [paper](https://rhoinc.github.io/publication-library/pubs/PhUSE2019_Childress.pdf) and [slides](https://rhoinc.github.io/publication-library/pubs/PhUSE2019_Childress_slides.pdf) from this project and others are available in our [Publications Library](https://rhoinc.github.io/publication-library/)_\n\nDownloading code from [GitHub](https://github.com/)® manually is straightforward: navigate to the repository website, download the ZIP file, and extract it to your working directory.\nHowever, because this process is manual it needs to be repeated whenever the repository changes, such as when the developer applies bug fixes or incorporates new features.\nSAS® and R provide users the tools to programmatically download and source repositories housed on GitHub.\n\nSAS and R both have a base set of functionality, but they differ in that R provides access to user-created packages, code bundles that extend R's functionality, hosted on services like the [Comprehensive R Archive Network](https://cran.r-project.org/) (CRAN) and GitHub.\nCRAN hosts established, vetted packages while GitHub tends to host more developmental packages.\nGitHub is not limited to R code, however, so the macro described here extends to SAS access to remote code repositories so ingrained in R development.\n\n## Sourcing Code from GitHub\n\nIn R, the [remotes package](https://cran.r-project.org/web/packages/remotes/index.html) contains a function named `install_github` that allows users to automate the installation of packages directly from GitHub:\n\n```R\n# Install and source the remotes package.\ninstall.packages(\"remotes\") \nlibrary(remotes) \n\n# Call install_github to download a repository directly from GitHub and then source it.\ninstall_github(\"RhoInc/datadigest\") \nlibrary(datadigest)\n```\n\nSAS lacks built-in functionality to simultaneously download and install code from GitHub, which prompted the creation of the SAS macro `%install_github` (available at [RhoInc/sas-install-github](https://github.com/RhoInc/sas-install-github)).\nThis macro behaves much like the corresponding R package.\nAfter a one-time manual download and install of the `%install_github` macro itself, SAS users are henceforth able to use the macro to automagically download and install other SAS code directly from GitHub.\n\n```SAS\n* Source the install_github program;\n%include \"my/utility/macros/install_github.sas\";\n\n* Call install_github to download and source a .sas file directly from GitHub;\n%install_github(\n    repo = RhoInc/violinPlot,\n    file = src/violinPlot.sas\n); \n\n* or to download and source a collection of .sas files stored in a single folder;\n%install_github(\n    repo = RhoInc/sas-codebook,\n    folder = Macros\n); \n```\n\n## Examples!\n\nFor demonstration, let's generate graphical data codebooks in both R and SAS.\nRho developed an R package named [datadigest](https://github.com/RhoInc/datadigest) that produces an interactive summary of a tabular dataset by column:\n\n```R\nremotes::install_github(\n    'RhoInc/datadigest'\n)\n\ndatadigest::codebook(\n    data = mtcars\n)\n```\n\n<img style=\"margin:0 auto\" src=\"{{ site.baseurl }}/images/2019-05-01-Make-GitHub-Your-Code-Repository-r-example.png\" align=\"center\" />\n\nWith the same idea in mind Rho also developed a SAS package that produces static summaries of SAS datasets by variable:\n\n```SAS\n%install_github(\n    repo = RhoInc/sas-codebook,\n    folder = Macros\n);\n\n%codebook_generic(\n    data = sashelp.cars\n);\n```\n<img style=\"margin:0 auto\" src=\"{{ site.baseurl }}/images/2019-05-01-Make-GitHub-Your-Code-Repository-sas-example.png\" align=\"center\" />\n\nTo access R or SAS code directly from GitHub without the hassle of a manual download, use the `install_github` function from the R package remotes or the SAS macro `%install_github` to help automate the process.\nWith these functions, programmers can access and continue their work anywhere with an internet connection, effectively becoming workstation-agnostic.\nGitHub's API extends the advantage of remote code repositories to SAS users, a capability R users have enjoyed for years.\n"
    },
    {
        "name": "2019-07-10-CRANsearcher-package-discovery.md",
        "path": "_posts/2019-07-10-CRANsearcher-package-discovery.md",
        "sha": "fd752f55435571b85357675b800017495bc8cf81",
        "size": 4745,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-07-10-CRANsearcher-package-discovery.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-07-10-CRANsearcher-package-discovery.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/fd752f55435571b85357675b800017495bc8cf81",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-07-10-CRANsearcher-package-discovery.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-07-10-CRANsearcher-package-discovery.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/fd752f55435571b85357675b800017495bc8cf81",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-07-10-CRANsearcher-package-discovery.md"
        },
        "md": "---\nlayout: post\ntitle: CRANsearcher - R package discovery made simple\nauthor: Becca Krouse and Agustin Calatroni\n---\n\nIt's a familiar story to many of us: we're working along and find that we need something very specific.  It could be a function or macro, or maybe an analysis technique.  It's also probably going to be quite difficult to create from scratch.  So we wonder, maybe this has been done before?  \n\nAs data scientists, exploratory analyses performed using emerging techniques are a regular part of the job.  We are pushing the limits of research and  constantly trying to discover and compare existing methods. We often find ourselves taking inventory of our analytical toolbox and trying to avoid reinventing the wheel.  Much of our data science work at Rho is performed using R, which offers a vast and rapidly growing ecosystem of [packages](https://cran.r-project.org/web/packages/available_packages_by_name.html).  Indeed, R packages extend from visualization to Bayesian inference, and from spatial analyses to pharmacokinetics. There is probably not an area of quantitative research that isn't represented by at least one R package.  R's great strength, however, can also be a weakness.  To answer the question of \"has someone already created a tool for this\" or \"what is the best way to do X\", we find ourselves navigating package websites, subscribing to blogs, and doing lots of googling. Unfortunately, this is also a diversion from our usual analysis workflow and is not always productive.   \n\nIn 2017, the 10,000th R package was published to CRAN and this became a hot topic in the R community.  It turns out we were not the only people struggling to navigate through all of the options.  This provided the last bit of motivation we needed to create our own solution.  Thus, the idea of `CRANsearcher` was born to fulfill an unmet need.\n\nWe went about building `CRANsearcher` with the analysis workflow in mind.  The application, which allows for efficient navigation of tens of thousands of R packages, can be run directly from R.    `CRANsearcher` is launched with the click of a button in RStudio. As shown below, it loads the entire CRAN package database (in real time) into a table that is sortable and filterable by release date.  The user can perform multi-term searches to discover packages through their names and descriptions.  Packages can be explored further through external links and installed with the click of a button.\n\n<img src=\"https://raw.githubusercontent.com/RhoInc/CRANsearcher/master/inst/image/gif/CRANsearcher_addin.gif\"/>\n\nAlthough this tool immediately became an asset for internal R users, we were surprised by how quickly it was embraced by the larger community.  We strongly believed this application could be useful to others, so we hosted its code on the Rho [GitHub site](https://github.com/RhoInc/CRANsearcher).  To date, the package has been downloaded almost 10,000 times since it's release in June 2017. We've also received great [feedback](https://twitter.com/juliasilge/status/866796243447463937), external [issues](https://github.com/RhoInc/CRANsearcher/issues?q=is%3Aissue+is%3Aclosed) for feature requests/bugs, and thoughtfully contributed [code](https://github.com/RhoInc/CRANsearcher/pulls?q=is%3Apr+is%3Aclosed+author%3Arpodcast). Sharing this code publicly has been a wonderful lesson in the power of community and collaboration, as well as innovation and transparency, all ideals we value in the Data Science group.  \n\nAs previously mentioned, at the time of `CRANsearcher`'s release, there were many related discussions happening in the R community.  In fact, we were fortunate to participate in a special session at UseR! 2017 conference called \"Navigating the R Package Universe\", which presented tools and strategies for finding and/or assessing packages.  Read Julia Silge's excellent follow-up blog post [here](https://juliasilge.com/blog/navigating-packages/). It has been incredibly rewarding to be a part of this community effort to develop supports around discovering new tools. \n\nIn summary, we would like to share the two lessons we learned from this experience. First, innovation doesn't need to be something that is difficult to reach. Indeed, CRANsearcher is simply a web scraping tool with a simple interface. Its success came because there was a need and we took the time to code it so that we can work more effectively in the future.  Second, you are not alone. Get the structure ready and there are plenty of colleagues out there ready to pitch in so that the effort is collective.\n\n`CRANsearcher` is available on [CRAN](https://cran.r-project.org/web/packages/CRANsearcher/index.html) and can be utilized as an Rstudio add-in or Shiny application.  \n"
    },
    {
        "name": "2019-08-16-Head-in-the-Word-Clouds.md",
        "path": "_posts/2019-08-16-Head-in-the-Word-Clouds.md",
        "sha": "140d37f1c4c737a63da98beb2380339c10d3790e",
        "size": 4185,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-08-16-Head-in-the-Word-Clouds.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-08-16-Head-in-the-Word-Clouds.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/140d37f1c4c737a63da98beb2380339c10d3790e",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-08-16-Head-in-the-Word-Clouds.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-08-16-Head-in-the-Word-Clouds.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/140d37f1c4c737a63da98beb2380339c10d3790e",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-08-16-Head-in-the-Word-Clouds.md"
        },
        "md": "---\nlayout: post\ntitle: Head in the (Word) Clouds, Feet on the Ground\nauthor: Ryan Bailey\n---\n\nOne of the teams I used to work on at my company had a tradition of creating friendly little word clouds that they would printout and give to team members on their birthday.  They were easy to make, and a fun alternative to the standard birthday card, but I never gave word clouds much serious thought as a data visualization tool.  To me, they were merely a fun diversion and a nice decoration to liven up my drab cubicle walls.\n\nIt turns out that word clouds are a popular data visualization tool, especially for displaying word frequency in a given body of text.  The most common approach is to correlate the size of the words in the cloud with how frequently the word appears.  Ergo, the larger the word, the more often it showed up.  Here's an example made from the text on our company's [public homepage](http://www.rhoworld.com).\n\n<img src=\"{{ site.baseurl }}/images/wordcloud_Rho.png\"/>\n\nNo surprise, the company name, \"Rho\" is the largest because it appears most often, followed by the words \"Clinical\" and \"Research\" (Rho is a clinical research organization).\n\nSo, this can certainly be an interesting way to visualize data, but something about the word cloud makes it feel less \"professional\" than some of our more tried and true visualization tools - like histograms, line graphs, and box plots.  It feels more like a middle school art project than an analysis tool.  \n\nSo, I was curious to see if I could find any information about the usefulness and reliability of word clouds as a robust visualization method.  Google led me to [this article](https://medium.com/@FILWD/taking-word-clouds-apart-alternative-designs-for-word-clouds-and-some-research-based-guidelines-df91129aa806) by Enrico Bertini, Associate Professor of Computer Science and Engineering at NYU, about deconstructing word clouds.  Bertini and his colleagues looked at the design of word clouds and identified 3 key layout strategies and 5 information encoding principles, which they used to create 15 different word cloud designs.  Then they identified a set of 4 tasks for which word clouds might commonly be used, and asked a simple question: which designs were most effective at completing each task?\n\nYou can read the article to get the nuance, but in summary they found that:\n1. Using supplemental graphics (e.g., bars, circles) overlaid with the words was most effective for assessing quantitative values of a point. \n2. Using varied font size and color intensity were most effective when the task was to search for individual words, but the utility of these font properties is most pronounced when the font is large - the smaller the font, the harder it is to perceive the differences.  (You can get a good feel for this challenge in our example above.  Once you get below the top 3-4 words, it becomes hard to distinguish the difference between individual words.)  \n3. The advantages described above are diminished and inconclusive for tasks of greater complexity.\n4. Sometimes, a simple list was more effective at achieving the desired result than using the more complex visualization of a word cloud.\n\nAll of the results seem pretty intuitive, but having these quantitative results helps us when it comes to making decisions about visualizations.  In our Data Science team, we are often tasked with coming up with \"the right visualization for the job.\"  Digging into research like this and understanding concepts like cognitive psychology, perception, and visual processing help us improve how we work. \n\nSo, what's the verdict on word clouds?  They have some value for visualization, but for much of our work, we probably have better visualization methods at our disposal.  Still, word clouds have a certain aesthetic appeal to them.  After all, I've yet to receive a birthday bar chart or scatter plot that made its way up on my cube walls.    \n\t\nFor a more in-depth look, you can read the [conference paper](https://static1.squarespace.com/static/5502f56fe4b0aa4bfbdae0a8/t/599a547af9a61eee6b38cf72/1503286395089/infovis17-word-clouds-apart.pdf) Bertini and his colleagues presented at IEEE Viz.\n"
    },
    {
        "name": "2019-09-12-Text-Mining-in-AAI-Part-1.md",
        "path": "_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md",
        "sha": "839faaa17e689f110d884a179647c98f16e96aca",
        "size": 14833,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/839faaa17e689f110d884a179647c98f16e96aca",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/839faaa17e689f110d884a179647c98f16e96aca",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2019-09-12-Text-Mining-in-AAI-Part-1.md"
        },
        "md": "---\nlayout: post\ntitle: Text Mining in Asthma, Allergy and Immunology - Part 1 of 2\nauthor: Preston Burns and Becca Krouse\n---\n\nIn the field of clinical research, many important deliverables exist in the format of a PDF or other text-based document. Examples range from Protocols, SAPs, and CRFs to Manuals and Reports. These documents are essential for guiding research and disseminating results, but Researchers already derive great value from these documents as they read and reference them throughout the life of a study. But what if we could extract even more value from these same resources, even long after a study has been completed?  This idea motivated our interest in text mining, which is an extensive analytical domain centered on deriving quality information from text documents.  To showcase our explorations into the world of text mining, we present this blog post focusing on some of the simpler techniques we applied to study protocols.\n\nWe began by selecting a set of 15 protocols from studies within the Inner City Asthma Consortium  (ICAC). Each study captures a unique aspect of the disease, and some are more alike than others. From these 15 ICAC protocols, we obtained word counts, and calculated a statistic called TF-IDF (term frequency-inverse document frequency). TF-IDF is a metric capturing the *uniqueness* and *frequency* of a word that appears in a document.  For example, if we decided to only use raw term frequency as our metric of importance, the word ‘Asthma’ would receive a high score for each of the documents, but that doesn’t help us understand what makes each document unique. By penalizing these common words, TF-IDF helps us find words that are *meaningful* rather than just frequent. Using TF-IDF values, we plotted the top 12 most meaningful words in each document:\n\n## Top 12 Meaningful Words by Study\n<img src=\"{{ site.baseurl }}/images/Top-12-Meaningful-Words-By-Study-Cropped.png\"/>\n<div markdown=\"1\">\n<details markdown=\"1\"><summary>Graphic Code</summary>\n\n```R\n#################################################\n#   Load libraries\n#################################################\nlibrary(tidyverse)\n\n#devtools::install_github(\"dgrtwo/drlib\") #NEED TO INSTALL THIS PACKAGE FOR FACETS TO DESCEND\nlibrary(drlib)\n\n#################################################\n#   Set working directory\n#################################################\nsetwd(\"./prog\")\n\n#################################################\n#    Load data\n#################################################\ndp <- readRDS(\"../data/icac_protocols.Rds\")\n\n\n#################################################\n#    Figure - top words by study based on tf-idf\n#################################################\n\npdf(file = \"study_top12word_barchart.pdf\", width=20, height=12)\n\ndp %>%\n  group_by(study) %>%\n  top_n(12, tf_idf) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, tf_idf)) %>%\n  ggplot(aes(reorder_within(word, tf_idf, study), tf_idf)) +\n  geom_col(show.legend = FALSE, fill=\"#0072B2\") +\n  scale_x_reordered() +\n  facet_wrap(~ study, scales = \"free_y\", ncol = 5) +\n  xlab(\"Word\")+\n  ylab(\"TF-IDF\") +\n  coord_flip() +theme_bw() +\n  theme(axis.title=element_text(size=16), strip.text = element_text(size=14), axis.text=element_text(size=13),\n        plot.title = element_text(size=20)) +\n  ggtitle('Top 12 Meaningful Words by Study')\n\ndev.off()\n```\n</details>\n</div>\n<br>\nIn these plots, each panel represents a study/document, the y-axis contains the top 12 words by document, and the x-axis shows the TF-IDF.  Notice that TF-IDF is comparable between documents.  For example, “extract” is uniquely and commonly found in multiple immunotherapy studies such as SCITCO, SCITMO, and SCSS, while “registry” is unique to RACR2, the only registry study of the group.  For this reason, the bar for “extract” has a lower magnitude than the bar for “registry”.  The top words in the panels give us clues about key features of the studies.  For example, “Xolair”/”omalizumab” are treatments provided in both ICATA and PROSE, and “mepolizumab” is the treatment given in MUPPITS-2.\n\nSo why should you care about this simple technique?\n\nWe just turned documents into numbers - and numbers unlock efficient analysis. Finding answers to important questions about these documents no longer requires reading all 15 of them. Let’s see what answers we can find!\n\nUsing this metric as our base, we can apply another common text mining technique to determine the similarity of documents: cosine similarity. The following heatmap displays the results of this analysis; the darker the square the more similar the documents are.\n\n## Heatmap of Cosine Similarity between Study Protocols\n<img src=\"{{ site.baseurl }}/images/Heatmap-of-Cosine-Similarity-between-Study-Protocols.png\"/>\n<div markdown=\"1\">\n<details markdown=\"1\"><summary>Graphic Code</summary>\n<br>\n```R\n#################################################\n#   Load libraries\n#################################################\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(proxy)\nlibrary(corrplot)\n\n#################################################\n#   Set working directory\n#################################################\nsetwd(\"./prog\")\n\n#################################################\n#    Load data\n#################################################\ndp_sim <- readRDS(\"../data/icac_similarity.Rds\")\n\n\n#################################################\n#    Figure - top words by study based on tf-idf\n#################################################\n\npdf(file = \"study_similarity_corrplot.pdf\", width=12, height=10)\n\n\ncol <- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\ncorrplot(corr=dp_sim, method=\"color\",\n         col =  col(20),\n         type=\"upper\",\n         order=\"hclust\",\n         hclust.method = \"ward.D2\",\n         tl.cex=1.3,\n         cl.cex=1.2,\n         number.cex=1.2,\n         addCoef.col = \"gray50\", addCoefasPercent = FALSE,\n         tl.col=\"black\", tl.srt=45,\n         diag=FALSE,\n         cl.lim=c(0,1),\n         cl.length=11,\n         mar=c(1,1,1,1), is.corr = FALSE\n)\n\ndev.off()\n```\n</details>\n</div>\n<br>\nStrong similarity scores exist between the immunotherapy studies (SCITCO, SCITMO, SCSS, BioCSI, and BioCSI2) and a few other small groups.  For example, PROSE and ICATA share a very dark square, as they are highly similar studies due to their treatment (Omalizumab) and outcome a shared endpoint (exacerbations). Otherwise we can see that there is minimal relative similarity across the other studies.\n\nHowever, there may be some nuances in the relationships that are hard to see. Let’s re-visualize these similarities using a network diagram, driven by TF-IDF as the metric. Each node will be a study protocol, and the strengths of the relationships between protocols will be represented by the thickness and darkness of the connection.\n\n## Network of Cosine Similarity between Study Protocols\n<img src=\"{{ site.baseurl }}/images/Network-of-Cosine-Similarity-between-Study-Protocols.png\"/>\n<div markdown=\"1\">\n<details markdown=\"1\"><summary>Graphic Code</summary>\n\n```R\n#################################################\n#   Load libraries\n#################################################\nlibrary(qgraph)\n\n\n\n#################################################\n#   Set working directory\n#################################################\nsetwd(\"./prog\")\n\n#################################################\n#    Load data\n#################################################\ndp_sim <- readRDS(\"../data/icac_similarity.Rds\")\n\n\n#################################################\n#    Figure - top words by study based on tf-idf\n#################################################\n\npdf(file = \"study_similarity_network.pdf\", width=10, height=8)\n\nqgraph(dp_sim, layout='spring', vsize=8, node.width =1.2, label.cex=1.2, labels = colnames(dp_sim), minimum = 0.05)\n\n\n\ndev.off()\n```\n\n</details>\n</div>\n<br>\nThat’s much better. Our findings from the heat map are confirmed: the immunotherapy studies are closely tied together with a few other strong associations in the network. It also looks like some natural groups are forming between the protocols. Let’s see if we can cluster them into groups using hierarchical cluster analysis, again using TF-IDF as the metric.\n\n## Study Protocol Clusters\n<img src=\"{{ site.baseurl }}/images/Study-Protocol-Clusters.png\"/>\n<div markdown=\"1\">\n<details markdown=\"1\"><summary>Graphic Code</summary>\n\n```R\n#################################################\n#   Load libraries\n#################################################\n\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(proxy)\nlibrary(dendextend)\nlibrary(RColorBrewer)\n\n#################################################\n#   Set working directory\n#################################################\nsetwd(\"./prog\")\n\n#################################################\n#    Load data\n#################################################\ndp <- readRDS(\"../data/icac_protocols.Rds\")\n\n\n#################################################\n#    Figure - top words by study based on tf-idf\n#################################################\n\npdf(file = \"study_similarity_cluster.pdf\", width=10, height=6)\n\nlabels<- c('Immunotherapy','','','','Omalizumab','MUPPITS','Minimal Intervention')\n\ncast_tdm(dp, word, study, tf_idf) %>%\n  as.matrix %>%\n  t()  %>% probably could have just used cast_dtm...\n  dist(method='cosine')  %>%\n  hclust(method=\"ward.D2\") %>%\n  as.dendrogram()  %>%\n  color_branches(k=7, col=brewer.pal(9,'Set1')[-c(6:7)],groupLabels=labels, cex=1.2)  %>%\n  set(\"labels_cex\", 1.1) %>%\n  plot(yaxt='n')\n\n\ndev.off()\n```\n\n</details>\n</div>\n<br>\nHere are the results of the cluster analysis in the form of a dendrogram.  Short branches following splits indicate similarity, while longer branches following splits reflect large differences between the studies.  As you can see, the analysis yielded 7 clusters, leaving RACR2, CoNAC, and Epigenetics in their own individual clusters. Now that we’ve defined our clusters, how can we determine what makes each one unique?  Below we pooled the documents in each cluster and recalculated the TF-IDF values to answer this question the same way we did in the first figure.\n\n## Top TF-IDF words by Cluster\n<img src=\"{{ site.baseurl }}/images/Top-TF-IDF-words-By-Cluster.png\"/>\n<div markdown=\"1\">\n<details markdown=\"1\"><summary>Graphic Code</summary>\n\n```R\n#################################################\n#   Load libraries\n#################################################\n\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n#devtools::install_github(\"dgrtwo/drlib\") #NEED TO INSTALL THIS PACKAGE FOR FACETS TO DESCEND\nlibrary(drlib)\n\n\n\n#################################################\n#   Set working directory\n#################################################\nsetwd(\"./prog\")\n\n#################################################\n#    Load data\n#################################################\ndp <- readRDS(\"../data/cluster_tfidf.Rds\")\n\n\n#################################################\n#    Figure - top words by study based on tf-idf\n#################################################\n\npdf(file = \"cluster_top12word_barchart.pdf\", width=17, height=9)\n\n#Plot Tf-IDF by cluster\ndp %>%\n  group_by(clust2) %>%\n  top_n(12, tf_idf) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, tf_idf)) %>%\n  ggplot(aes(reorder_within(word, tf_idf, clust2), tf_idf, fill = clust2)) +\n  geom_col(show.legend = FALSE) +\n  scale_x_reordered() +\n  facet_wrap(~ clust2, scales = \"free_y\", nrow = 2) +\n  xlab(\"Word\")+\n  ylab(\"TF-IDF\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.title=element_text(size=18), strip.text = element_text(size=18), axis.text=element_text(size=14),\n        plot.title = element_text(size=20)) +\n  scale_fill_manual(values = brewer.pal(9,'Set1')[-c(6:7)])\n\n\ndev.off()\n```\n\n</details>\n</div>\n<br>\nThe top words for the clusters often provide convenient cluster names or clearly show shared treatments or outcomes as key commonalities. For some, like ‘Minimal Intervention’, clusters have formed that we might not have expected, but these are often the most exciting as they provide information we would not have found otherwise.\n\nUsing text mining we’ve been able to determine what makes documents unique, and explore relationships between them.  What other possibilities are thereexist for text mining in clinical trials research?\n\nThat’s what we’ll touch on next time when we scratch the surface of some of the applications for text mining in clinical trials research in Part 2.\n## Additional Info and References\n\nIn case you haven't noticed, the code for each graphic is provided beneath it. The protocols that served as data for this blog post, however, cannot be shared. Here's a code snippet from our data derivation process that'll give you an idea of what we did:\n<details markdown=\"1\"><summary>Data Derivation Code</summary>\n\n### Code for generating tf-idf matrix\n<div markdown=\"1\">\n\n```R\nlibrary(tidyverse)\nlibrary(tidytext)\n\ndp <- data_frame(path = protocol_files,\n                 doc = basename(protocol_files)) %>%\n  separate(doc, c(\"study\",\"extra\"), extra=\"merge\") %>%\n  mutate(study = case_when(\n    study==\"Protocol\" ~ \"URECA\",\n    study==\"ICAC\" ~ \"MUPPITS-1\",\n    study==\"MUPPITS\" ~ \"MUPPITS-2\",\n    TRUE ~ study)) %>%\n  mutate(text = map_chr(path, ~ pdftools::pdf_text(.) %>%  \n                          paste(., collapse=\" \"))) %>%\n  unnest_tokens(word, text) %>%       ### 1 rec per word per doc\n  #filter(!str_detect(word, \"[0-9]\") & !str_detect(word, \"[:punct:]\"))\n  anti_join(stop_words) %>%           ### remove stop words\n  mutate(word = str_replace_all(word, \"[0-9]\", \"\"),       #remove numbers from words\n         word = str_replace_all(word, \"[:punct:]\", \"\"),   #remove punctution from words\n         word = trimws(word)) %>%                         #trim white space off the ends of words\n  anti_join(stop_words) %>%           ### remove stop words again\n  filter(!is.na(word) & !word==\"\") %>%                    # remove missing/empty strings\n  filter(!nchar(word)==1) %>%\n  select(study, word)%>%\n  count(study, word)  %>%  \n  bind_tf_idf(word, study, n) %>%\n  arrange(desc(tf_idf))\n```\n</div>\n\n### Code for generating similarity matrix\n<div markdown=\"1\">\n\n```R\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(proxy)\n\ndp_sim <-dp %>%\n  cast_dtm(study, word, tf_idf) %>% #Create Document-Term Matrix\n  as.matrix %>%\n  simil(method='cosine', diag = TRUE) %>% #Calculate cosine similarities\n  as.matrix(diag=0)\n```\n</div>\n</details>\n<br>\nThe [Text Mining with R](https://www.tidytextmining.com/) (Silge & Robinson 2019) book was very helpful in the creation of this post!\n\nThe following R packages were used in this post:\n- tidyverse\n- tidytext\n- proxy\n- dendextend\n- corrplot\n- qgraph\n- RColorBrewer\n- drlib (helpful for ggplot facets)\n"
    },
    {
        "name": "2020-01-22-custom-safetyGraphics-workflows.md",
        "path": "_posts/2020-01-22-custom-safetyGraphics-workflows.md",
        "sha": "7ecab2cbf23dd43a78e4f2e327f994fbc59a5fd0",
        "size": 2152,
        "url": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2020-01-22-custom-safetyGraphics-workflows.md?ref=master",
        "html_url": "https://github.com/RhoInc/blog/blob/master/_posts/2020-01-22-custom-safetyGraphics-workflows.md",
        "git_url": "https://api.github.com/repos/RhoInc/blog/git/blobs/7ecab2cbf23dd43a78e4f2e327f994fbc59a5fd0",
        "download_url": "https://raw.githubusercontent.com/RhoInc/blog/master/_posts/2020-01-22-custom-safetyGraphics-workflows.md",
        "type": "file",
        "_links": {
            "self": "https://api.github.com/repos/RhoInc/blog/contents/_posts/2020-01-22-custom-safetyGraphics-workflows.md?ref=master",
            "git": "https://api.github.com/repos/RhoInc/blog/git/blobs/7ecab2cbf23dd43a78e4f2e327f994fbc59a5fd0",
            "html": "https://github.com/RhoInc/blog/blob/master/_posts/2020-01-22-custom-safetyGraphics-workflows.md"
        },
        "md": "---\nlayout: post\ntitle: Custom safetyGraphics Workflows\nauthor: Jeremy Wildfire\n---\n\nThe `safetyGraphics` R package now supports custom workflows allowing users to preload their own charts and data sets in the safetyGraphics Shiny Application. The best way to learn more is the new [Custom Workflows vignette](https://cran.r-project.org/web/packages/safetyGraphics/vignettes/customWorkflows.html) - which has been briefly summarized below.\n\nThe new [v1.1 release](https://github.com/SafetyGraphics/safetyGraphics/releases/tag/v1.1.0) of [safetyGraphics](https://github.com/SafetyGraphics/safetyGraphics) is [available now on CRAN](https://cran.r-project.org/web/packages/safetyGraphics/index.html).\n  \n# Loading data\n\nLoading data in to the app is easy! Just run `safetyGraphicsApp(loadData=TRUE)` to preload all data.frames from your current R session in a new instance of the safetyGraphics Shiny app.\n\n# Loading Charts\n\nLoading custom charts is just slightly more complex. There are 4 steps required to create a custom chart for use in `safetyGraphics`:\n\n1. Create custom chart code\n2. Add new settings to the app (if needed)\n3. Add the chart to the app\n4. Initialize the app\n\nFor example, to create a trivially simple custom chart, make a file called `customSettings.R` with the following code: \n\n```\n# Step 1 - Write custom chart code \nhelloWorld <- function(data,settings){\n  plot(-1:1, -1:1)\n  text(runif(20, -1,1),runif(20, -1,1),\"Hello World\")\n}\n\n# Step 2 - Initialize Custom Settings \n# Not Applicable!\n\n# Step 3 - Initialize the custom chart \naddChart( \n  chart=”hello_world”,\n  main=”helloWorld\",\n  label=”Hello World”, \n)\n```\n\nThen initialize the app (Step 4) by running: \n\n```\nsetwd('/path/to/the/file/above')\nsafetyGraphicsApp()\n```\n\nOnce the app opens, click the charts tab to view the new custom \"hello_world\" chart. \n\n<img src=\"https://user-images.githubusercontent.com/3680095/71821298-c0080980-305f-11ea-979e-6574ac30f706.png\" style='max-width:700px'>\n\nAgain, see the [Custom Workflows vignette](https://cran.r-project.org/web/packages/safetyGraphics/vignettes/customWorkflows.html) \n\n\n\ndetails and more complex examples.\n"
    }
]